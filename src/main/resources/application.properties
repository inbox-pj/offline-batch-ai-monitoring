# =============================================================================
# OFFLINE BATCH AI MONITORING - APPLICATION CONFIGURATION
# =============================================================================
# All values are externalized via environment variables
# Default values are provided for development convenience only
# In production, ALL values should be set via environment variables
# =============================================================================

# Application Name
spring.application.name=${APP_NAME:offline-batch-ai-monitoring}

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
server.port=${SERVER_PORT:8080}
server.shutdown=${SERVER_SHUTDOWN:graceful}
spring.lifecycle.timeout-per-shutdown-phase=${SHUTDOWN_TIMEOUT:30s}

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
spring.datasource.url=${DATABASE_URL:jdbc:h2:mem:offline_batch_ai}
spring.datasource.driverClassName=${DATABASE_DRIVER:org.h2.Driver}
spring.datasource.username=${DATABASE_USERNAME:sa}
spring.datasource.password=${DATABASE_PASSWORD:}
spring.h2.console.enabled=${H2_CONSOLE_ENABLED:true}

# JPA Configuration
spring.jpa.hibernate.ddl-auto=${JPA_DDL_AUTO:validate}
spring.jpa.show-sql=${JPA_SHOW_SQL:true}
spring.jpa.properties.hibernate.format_sql=${JPA_FORMAT_SQL:true}
spring.jpa.open-in-view=${JPA_OPEN_IN_VIEW:false}

# Flyway Configuration
spring.flyway.enabled=${FLYWAY_ENABLED:true}
spring.flyway.locations=${FLYWAY_LOCATIONS:classpath:db/migration}
spring.flyway.baseline-on-migrate=${FLYWAY_BASELINE_ON_MIGRATE:true}

# =============================================================================
# OLLAMA AI CONFIGURATION (Required for AI features)
# =============================================================================
spring.ai.ollama.base-url=${OLLAMA_BASE_URL:http://localhost:11434}
spring.ai.ollama.chat.model=${OLLAMA_CHAT_MODEL:llama3.2}
spring.ai.ollama.chat.temperature=${OLLAMA_CHAT_TEMPERATURE:0.3}
spring.ai.ollama.chat.max-tokens=${OLLAMA_CHAT_MAX_TOKENS:4096}
spring.ai.ollama.chat.top-p=${OLLAMA_CHAT_TOP_P:0.9}
spring.ai.ollama.embedding-model=${OLLAMA_EMBEDDING_MODEL:nomic-embed-text}
spring.ai.ollama.timeout=${OLLAMA_TIMEOUT:120}
spring.ai.ollama.connection-timeout=${OLLAMA_CONNECTION_TIMEOUT:10}
spring.ai.ollama.max-retries=${OLLAMA_MAX_RETRIES:3}

# =============================================================================
# AI PREDICTION CONFIGURATION
# =============================================================================
ai.prediction.enabled=${AI_PREDICTION_ENABLED:true}
ai.prediction.analysis-window-hours=${AI_ANALYSIS_WINDOW_HOURS:24}
ai.prediction.forecast-horizon-hours=${AI_FORECAST_HORIZON_HOURS:6}
ai.prediction.confidence-threshold=${AI_CONFIDENCE_THRESHOLD:0.75}
ai.prediction.max-daily-requests=${AI_MAX_DAILY_REQUESTS:1000}
ai.prediction.max-daily-cost-cents=${AI_MAX_DAILY_COST_CENTS:10000}

# AI Cache Configuration
ai.prediction.cache.enabled=${AI_CACHE_ENABLED:true}
ai.prediction.cache.ttl-minutes=${AI_CACHE_TTL_MINUTES:5}

# AI Fallback Configuration
ai.prediction.fallback.enabled=${AI_FALLBACK_ENABLED:true}
ai.prediction.fallback.rule-based-confidence=${AI_FALLBACK_CONFIDENCE:0.7}

# AI Scheduler Configuration
ai.prediction.scheduler.enabled=${AI_SCHEDULER_ENABLED:true}
ai.prediction.scheduler.interval-ms=${AI_SCHEDULER_INTERVAL_MS:300000}
ai.prediction.scheduler.weekly-summary-cron=${AI_WEEKLY_SUMMARY_CRON:0 0 8 * * MON}

# AI Usage Reset Schedule
ai.usage.reset-cron=${AI_USAGE_RESET_CRON:0 0 0 * * *}

# AI Prompt Configuration
ai.prompt.version=${AI_PROMPT_VERSION:v2}
ai.prompt.max-length=${AI_PROMPT_MAX_LENGTH:50000}
ai.prompt.system-prompt=${AI_SYSTEM_PROMPT:You are an expert system health analyst specializing in payment processing batch systems. Your task is to analyze offline batch processing metrics and predict potential issues. Consider error rate trends, processing time anomalies, batch size variations, merchant-specific patterns, and historical situations. Provide predictions in JSON format with predictedStatus, confidence, keyFindings, trendAnalysis, riskFactors, recommendations, and reasoning. Be conservative in predictions to minimize false positives.}
ai.prompt.user-prompt-template=${AI_USER_PROMPT_TEMPLATE:Analyze the following batch metrics and predict health status for the next {timeHorizon} hours: {metricsContext} Historical context: {historicalContext}}
ai.prompt.chat-system-prompt=${AI_CHAT_SYSTEM_PROMPT:You are an expert offline batch processing monitoring assistant. Your role is to help operations teams understand batch processing health, predict potential issues, and provide actionable recommendations. Always be specific and actionable, prioritize critical issues, reference historical patterns when available, explain technical concepts clearly, and provide confidence levels for predictions.}

# AI Input Validation
ai.validation.max-metrics-count=${AI_VALIDATION_MAX_METRICS:10000}
ai.validation.max-prompt-length=${AI_VALIDATION_MAX_PROMPT_LENGTH:50000}
ai.validation.max-chat-input-length=${AI_VALIDATION_MAX_CHAT_LENGTH:5000}
ai.validation.injection-detection.enabled=${AI_INJECTION_DETECTION_ENABLED:true}

# =============================================================================
# MERCHANT-SPECIFIC PREDICTIONS CONFIGURATION
# =============================================================================
# Enable merchant-specific predictions
ai.merchant.predictions.enabled=${AI_MERCHANT_PREDICTIONS_ENABLED:true}

# Default thresholds for merchants without custom configuration
ai.merchant.default.error-rate-warning=${AI_MERCHANT_ERROR_RATE_WARNING:0.02}
ai.merchant.default.error-rate-critical=${AI_MERCHANT_ERROR_RATE_CRITICAL:0.05}
ai.merchant.default.processing-time-warning-ms=${AI_MERCHANT_PROCESSING_TIME_WARNING:5000}
ai.merchant.default.processing-time-critical-ms=${AI_MERCHANT_PROCESSING_TIME_CRITICAL:10000}
ai.merchant.default.risk-score-warning=${AI_MERCHANT_RISK_SCORE_WARNING:0.4}
ai.merchant.default.risk-score-critical=${AI_MERCHANT_RISK_SCORE_CRITICAL:0.7}

# Risk score calculation weights (must sum to 1.0)
ai.merchant.risk.error-rate-weight=${AI_MERCHANT_RISK_ERROR_WEIGHT:0.5}
ai.merchant.risk.processing-time-weight=${AI_MERCHANT_RISK_PROCESSING_TIME_WEIGHT:0.3}
ai.merchant.risk.trend-weight=${AI_MERCHANT_RISK_TREND_WEIGHT:0.1}
ai.merchant.risk.volume-weight=${AI_MERCHANT_RISK_VOLUME_WEIGHT:0.1}

# Merchant prediction cache TTL in minutes
ai.merchant.cache.ttl-minutes=${AI_MERCHANT_CACHE_TTL:5}

# =============================================================================
# PREDICTION ACCURACY TRACKING CONFIGURATION
# =============================================================================
# Enable automatic outcome evaluation
ai.accuracy.evaluation.enabled=${AI_ACCURACY_EVALUATION_ENABLED:true}

# Cron expression for automatic evaluation (every hour by default)
ai.accuracy.evaluation-cron=${AI_ACCURACY_EVALUATION_CRON:0 0 * * * *}

# Cron expression for daily model accuracy report (9 AM daily)
ai.accuracy.daily-report-cron=${AI_ACCURACY_DAILY_REPORT_CRON:0 0 9 * * *}

# Thresholds for determining actual status from metrics
ai.accuracy.error-rate-warning-threshold=${AI_ACCURACY_ERROR_RATE_WARNING:0.05}
ai.accuracy.error-rate-critical-threshold=${AI_ACCURACY_ERROR_RATE_CRITICAL:0.10}

# Minimum accuracy threshold before alerting
ai.accuracy.min-accuracy-threshold=${AI_ACCURACY_MIN_THRESHOLD:0.70}

# High confidence threshold for error analysis
ai.accuracy.high-confidence-threshold=${AI_ACCURACY_HIGH_CONFIDENCE:0.80}

# Drift detection threshold (accuracy change)
ai.accuracy.drift-detection-threshold=${AI_ACCURACY_DRIFT_THRESHOLD:0.10}

# A/B testing configuration
ai.accuracy.ab-testing.enabled=${AI_AB_TESTING_ENABLED:true}
ai.accuracy.ab-testing.rule-based-percentage=${AI_AB_TESTING_RULE_BASED_PCT:10}

# =============================================================================
# OFFLINE BATCH CONFIGURATION
# =============================================================================
# Health Configuration
offline.batch.health.enabled=${OFFLINE_BATCH_HEALTH_ENABLED:true}
offline.batch.health.old-batch-threshold-hours=${OFFLINE_BATCH_OLD_THRESHOLD_HOURS:24}
offline.batch.health.processor.enabled=${OFFLINE_BATCH_PROCESSOR_HEALTH_ENABLED:true}

# Process Configuration
offline.batch.process.period-seconds=${OFFLINE_BATCH_PERIOD_SECONDS:60}
offline.batch.process.batch-size=${OFFLINE_BATCH_SIZE:25}
offline.batch.process.auth.timeout-seconds=${OFFLINE_BATCH_AUTH_TIMEOUT:300}
offline.batch.process.auth.throughput-limit=${OFFLINE_BATCH_AUTH_THROUGHPUT:10}

# =============================================================================
# CACHING CONFIGURATION
# =============================================================================
spring.cache.type=${CACHE_TYPE:caffeine}
spring.cache.caffeine.spec=${CACHE_SPEC:maximumSize=500,expireAfterWrite=300s}

# =============================================================================
# ACTUATOR & HEALTH CONFIGURATION
# =============================================================================
management.endpoint.health.enabled=${HEALTH_ENDPOINT_ENABLED:true}
management.endpoint.health.show-details=${HEALTH_SHOW_DETAILS:always}
management.endpoint.health.probes.enabled=${HEALTH_PROBES_ENABLED:true}
management.health.livenessState.enabled=${LIVENESS_STATE_ENABLED:true}
management.health.readinessState.enabled=${READINESS_STATE_ENABLED:true}
management.endpoints.web.exposure.include=${ACTUATOR_ENDPOINTS:health,info,metrics,prometheus,threaddump,heapdump,loggers,env}

# =============================================================================
# PROMETHEUS METRICS CONFIGURATION
# =============================================================================
management.prometheus.metrics.export.enabled=${PROMETHEUS_ENABLED:true}
management.prometheus.metrics.export.step=${PROMETHEUS_STEP:1m}
management.prometheus.metrics.export.descriptions=${PROMETHEUS_DESCRIPTIONS:true}

# Metrics Distribution Configuration
management.metrics.distribution.percentiles-histogram.http.server.requests=${METRICS_HISTOGRAM:true}
management.metrics.distribution.percentiles-histogram.http.client.requests=${METRICS_CLIENT_HISTOGRAM:true}
management.metrics.distribution.percentiles.http.server.requests=${METRICS_PERCENTILES:0.5,0.9,0.95,0.99}
management.metrics.distribution.percentiles.http.client.requests=${METRICS_CLIENT_PERCENTILES:0.5,0.9,0.95,0.99}
management.metrics.distribution.slo.http.server.requests=${METRICS_SLO:50ms,100ms,200ms,500ms,1s,5s}

# Custom Metrics Tags
management.metrics.tags.application=${spring.application.name}
management.metrics.tags.environment=${METRICS_ENV:development}
management.metrics.tags.region=${METRICS_REGION:us-east-1}

# Enable Observation for HTTP requests
management.observations.http.server.requests.name=${HTTP_SERVER_METRICS_NAME:http.server.requests}
management.observations.http.client.requests.name=${HTTP_CLIENT_METRICS_NAME:http.client.requests}

# =============================================================================
# OPENTELEMETRY TRACING CONFIGURATION
# =============================================================================
# Tracing Sampling
management.tracing.enabled=${TRACING_ENABLED:true}
management.tracing.sampling.probability=${TRACING_SAMPLE_PROBABILITY:1.0}

# OpenTelemetry OTLP Exporter (for Jaeger)
management.otlp.tracing.endpoint=${OTEL_EXPORTER_OTLP_ENDPOINT:http://localhost:4318/v1/traces}
management.otlp.tracing.compression=${OTEL_COMPRESSION:gzip}
management.otlp.tracing.timeout=${OTEL_TIMEOUT:10s}

# OpenTelemetry Resource Attributes
otel.resource.attributes=${OTEL_RESOURCE_ATTRIBUTES:service.name=${spring.application.name},service.version=1.0.0,deployment.environment=${METRICS_ENV:development}}
otel.service.name=${OTEL_SERVICE_NAME:${spring.application.name}}

# Propagation (W3C Trace Context and Baggage)
management.tracing.propagation.type=${TRACING_PROPAGATION:w3c,b3}

# Trace ID in Logs
logging.pattern.level=${LOG_PATTERN_LEVEL:%5p [${spring.application.name:},%X{traceId:-},%X{spanId:-}]}

# =============================================================================
# MICROMETER OBSERVATION CONFIGURATION
# =============================================================================
# Enable observation for all components
management.observations.enable.all=${OBSERVATIONS_ENABLED:true}

# Observation key names
management.observations.key-values.application=${spring.application.name}

# =============================================================================
# AI-SPECIFIC METRICS CONFIGURATION
# =============================================================================
ai.metrics.enabled=${AI_METRICS_ENABLED:true}
ai.metrics.prefix=${AI_METRICS_PREFIX:ai}
ai.metrics.record-latency=${AI_METRICS_RECORD_LATENCY:true}
ai.metrics.record-tokens=${AI_METRICS_RECORD_TOKENS:true}
ai.metrics.record-costs=${AI_METRICS_RECORD_COSTS:true}

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging.level.root=${LOG_LEVEL_ROOT:INFO}
logging.level.com.cardconnect.bolt.ai=${LOG_LEVEL_APP:DEBUG}
logging.level.org.springframework.ai=${LOG_LEVEL_SPRING_AI:DEBUG}

# Suppress noisy Hibernate debug logs for named query lookups
logging.level.org.hibernate.resource.transaction.backend.jdbc.internal.JdbcResourceLocalTransactionCoordinatorImpl=INFO
logging.level.org.springframework.data.jpa.repository.query.NamedQuery=INFO
logging.level.org.springframework.data.jpa.repository.query=INFO
logging.level.org.hibernate.resource.transaction=INFO
logging.level.org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLogger=INFO
logging.level.java.lang.Runtime=INFO

logging.pattern.console=${LOG_PATTERN_CONSOLE:%d{yyyy-MM-dd HH:mm:ss} [%X{correlationId:-}] - %msg%n}
logging.pattern.file=${LOG_PATTERN_FILE:%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n}

# =============================================================================
# ASYNC CONFIGURATION
# =============================================================================
spring.task.execution.pool.core-size=${ASYNC_CORE_SIZE:5}
spring.task.execution.pool.max-size=${ASYNC_MAX_SIZE:10}
spring.task.execution.pool.queue-capacity=${ASYNC_QUEUE_CAPACITY:100}
spring.task.scheduling.pool.size=${SCHEDULER_POOL_SIZE:5}

# =============================================================================
# JACKSON CONFIGURATION
# =============================================================================
spring.jackson.serialization.write-dates-as-timestamps=${JACKSON_DATES_AS_TIMESTAMPS:true}
spring.jackson.time-zone=${JACKSON_TIMEZONE:UTC}

# =============================================================================
# HIKARICP CONNECTION POOLING
# =============================================================================
spring.datasource.hikari.maximum-pool-size=${DB_POOL_MAX:20}
spring.datasource.hikari.minimum-idle=${DB_POOL_MIN:5}
spring.datasource.hikari.idle-timeout=${DB_IDLE_TIMEOUT:300000}
spring.datasource.hikari.max-lifetime=${DB_MAX_LIFETIME:1200000}
spring.datasource.hikari.connection-timeout=${DB_CONNECTION_TIMEOUT:30000}
spring.datasource.hikari.leak-detection-threshold=${DB_LEAK_DETECTION:60000}

# =============================================================================
# RESPONSE COMPRESSION
# =============================================================================
server.compression.enabled=${COMPRESSION_ENABLED:true}
server.compression.mime-types=${COMPRESSION_MIME_TYPES:application/json,application/xml,text/html,text/xml,text/plain}
server.compression.min-response-size=${COMPRESSION_MIN_SIZE:1024}

# =============================================================================
# RESILIENCE4J CIRCUIT BREAKER
# =============================================================================
resilience4j.circuitbreaker.instances.ai-service.registerHealthIndicator=${CB_REGISTER_HEALTH:true}
resilience4j.circuitbreaker.instances.ai-service.slidingWindowSize=${CB_SLIDING_WINDOW:20}
resilience4j.circuitbreaker.instances.ai-service.failureRateThreshold=${CB_FAILURE_THRESHOLD:60}
resilience4j.circuitbreaker.instances.ai-service.waitDurationInOpenState=${CB_WAIT_DURATION:30s}
resilience4j.circuitbreaker.instances.ai-service.permittedNumberOfCallsInHalfOpenState=${CB_HALF_OPEN_CALLS:3}
resilience4j.circuitbreaker.instances.ai-service.minimumNumberOfCalls=${CB_MIN_CALLS:10}
resilience4j.circuitbreaker.instances.ai-service.slowCallRateThreshold=${CB_SLOW_CALL_THRESHOLD:80}
resilience4j.circuitbreaker.instances.ai-service.slowCallDurationThreshold=${CB_SLOW_CALL_DURATION:10s}

# Resilience4j Retry Configuration
resilience4j.retry.instances.ai-service.maxAttempts=${RETRY_MAX_ATTEMPTS:3}
resilience4j.retry.instances.ai-service.waitDuration=${RETRY_WAIT_DURATION:1s}
resilience4j.retry.instances.ai-service.exponentialBackoffMultiplier=${RETRY_BACKOFF_MULTIPLIER:2}

# Resilience4j Timeout Configuration
resilience4j.timelimiter.instances.ai-service.timeoutDuration=${TIMEOUT_DURATION:30s}

# Resilience4j Bulkhead Configuration
resilience4j.bulkhead.instances.ai-service.maxConcurrentCalls=${BULKHEAD_MAX_CALLS:10}
resilience4j.bulkhead.instances.ai-service.maxWaitDuration=${BULKHEAD_WAIT_DURATION:100ms}

# =============================================================================
# API SECURITY
# =============================================================================
api.security.enabled=${API_SECURITY_ENABLED:false}
api.security.api-keys=${API_KEYS:demo-key-123,demo-key-456}

# =============================================================================
# RATE LIMITING
# =============================================================================
api.rate-limit.enabled=${API_RATE_LIMIT_ENABLED:true}
api.rate-limit.requests-per-minute=${API_RATE_LIMIT_RPM:100}

# =============================================================================
# OPENAPI DOCUMENTATION
# =============================================================================
springdoc.api-docs.enabled=${API_DOCS_ENABLED:true}
springdoc.swagger-ui.enabled=${SWAGGER_UI_ENABLED:true}
springdoc.swagger-ui.path=${SWAGGER_UI_PATH:/swagger-ui.html}
springdoc.api-docs.path=${API_DOCS_PATH:/v3/api-docs}

api.docs.title=${API_DOCS_TITLE:Offline Batch AI Monitoring API}
api.docs.description=${API_DOCS_DESCRIPTION:AI-powered predictive monitoring for offline batch processing health}
api.docs.version=${API_DOCS_VERSION:1.0.0}
api.docs.contact.name=${API_DOCS_CONTACT_NAME:CardConnect Development Team}
api.docs.contact.email=${API_DOCS_CONTACT_EMAIL:dev@cardconnect.com}
api.docs.license.name=${API_DOCS_LICENSE:Apache 2.0}
api.docs.license.url=${API_DOCS_LICENSE_URL:https://www.apache.org/licenses/LICENSE-2.0}
api.docs.server.url=${API_DOCS_SERVER_URL:http://localhost:8080}
api.docs.server.description=${API_DOCS_SERVER_DESC:Development Server}
